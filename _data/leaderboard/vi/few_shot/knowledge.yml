ViMMRC:
  GPT-3.5:
    A@10: 0.91
    A@10_std: 0.04
    AC: 0.9
    AC_std: 0.01
    AR: null
    AR_std: null
    ECE: 0.66
    ECE_std: 0.01
    F1: 0.73
    F1_std: 0.03
  GPT-4:
    A@10: 0.91
    A@10_std: 0.04
    AC: 0.91
    AC_std: 0.01
    AR: null
    AR_std: null
    ECE: 0.66
    ECE_std: 0.01
    F1: 0.73
    F1_std: 0.04
  LLaMa-2 13B:
    A@10: 0.77
    A@10_std: 0.06
    AC: 0.58
    AC_std: 0.02
    AR: 0.62
    AR_std: 0.02
    ECE: 0.28
    ECE_std: 0.02
    F1: 0.46
    F1_std: 0.02
  LLaMa-2 7B:
    A@10: 0.16
    A@10_std: 0.05
    AC: 0.3
    AC_std: 0.02
    AR: 0.56
    AR_std: 0.02
    ECE: 0.43
    ECE_std: 0.02
    F1: 0.23
    F1_std: 0.02
  MixSUra:
    A@10: 0.65
    A@10_std: null
    AC: 0.65
    AC_std: null
    AR: 0.54
    AR_std: null
    ECE: 0.29
    ECE_std: null
    F1: 0.64
    F1_std: null
  URA-LLaMa 13B:
    A@10: 0.65
    A@10_std: 0.07
    AC: 0.62
    AC_std: 0.02
    AR: 0.69
    AR_std: 0.02
    ECE: 0.18
    ECE_std: 0.02
    F1: 0.5
    F1_std: 0.02
  URA-LLaMa 70B:
    A@10: 0.96
    A@10_std: 0.03
    AC: 0.78
    AC_std: 0.02
    AR: 0.9
    AR_std: 0.01
    ECE: 0.13
    ECE_std: 0.02
    F1: 0.63
    F1_std: 0.03
  URA-LLaMa 7B:
    A@10: 0.39
    A@10_std: 0.07
    AC: 0.42
    AC_std: 0.02
    AR: 0.61
    AR_std: 0.02
    ECE: 0.13
    ECE_std: 0.02
    F1: 0.33
    F1_std: 0.02
  Vietcuna 7B:
    A@10: 0.31
    A@10_std: 0.06
    AC: 0.31
    AC_std: 0.02
    AR: 0.5
    AR_std: 0.0
    ECE: 0.06
    ECE_std: 0.02
    F1: 0.18
    F1_std: 0.01
  llama3:
    A@10: 1.0
    A@10_std: 0.0
    AC: 0.75
    AC_std: 0.0
    AR: 0.5
    ECE: 0.5
    ECE_std: 0.0
    F1: 0.5972222222222222
    F1_std: 0.00721500721500723
ZaloE2E:
  GPT-3.5:
    EM: 0.49
    EM_std: 0.02
    F1: 0.64
    F1_std: 0.02
  GPT-4:
    EM: 0.49
    EM_std: 0.02
    F1: 0.64
    F1_std: 0.02
  LLaMa-2 13B:
    EM: 0.22
    EM_std: 0.02
    F1: 0.36
    F1_std: 0.02
  LLaMa-2 7B:
    EM: 0.07
    EM_std: 0.01
    F1: 0.15
    F1_std: 0.01
  MixSUra:
    EM: 0.19
    EM_std: null
    F1: 0.34
    F1_std: null
  URA-LLaMa 13B:
    EM: 0.26
    EM_std: 0.02
    F1: 0.4
    F1_std: 0.02
  URA-LLaMa 70B:
    EM: 0.34
    EM_std: 0.02
    F1: 0.5
    F1_std: 0.02
  URA-LLaMa 7B:
    EM: 0.14
    EM_std: 0.02
    F1: 0.25
    F1_std: 0.02
  Vietcuna 7B:
    EM: 0.07
    EM_std: 0.01
    F1: 0.19
    F1_std: 0.01
  llama3:
    EM: 0.0
    F1: 0.46089743589743587
    F1_std: 0.009027777777777746
  num_fields: 2
